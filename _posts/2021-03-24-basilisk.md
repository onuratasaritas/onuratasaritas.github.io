---
published: true
---

so since i'm out of work until April 1st, i've been doing a ton of binge-reading some wiki pages and i thought maybe i'd share my thoughts superintelligent ai.

let me tell you about roko's basilisk.

> Roko’s basilisk is a thought experiment proposed in 2010 by the user Roko on the Less Wrong community blog. Roko used ideas in decision theory to argue that a sufficiently powerful AI agent would have an incentive to torture anyone who imagined the agent but didn't work to bring the agent into existence. The argument was called a "basilisk" because merely hearing the argument would supposedly put you at risk of torture from this hypothetical agent — a basilisk in this context is any information that harms or endangers the people who hear it.

it basically says that; there happens a rogue ai in the future that were to come about and punish/threaten those who did not do its bidding. that it would come up with a way to punish  people _today_ who are not helping it come into existence _earlier_ by working on it. the argument hypothises that computing power and human understanding of consciousness becomes so advanced that a superintelligent ai becomes possible, as does the capability to simulate and upload minds to a computer, thus allowing it to simulate life itself. this is horrifying in so many levels, for instance, the universe we're experiencing in our lives could be basically a simulation for predicting what a single person would react in a situation.

just by knowing the existence of roko's basilisk makes you a target. sleep well tonight.


